#!/bin/bash
# Starts and stops spark.

sparkVer="spark-1.0.0"
if [ -d "/var/run/spark/" ]; then
	pidWorker=`ls -alt /var/run/spark/ | grep spark-.*.Worker-.*.pid | head -1 | awk -F " " '{print $9}'`
fi

pidFile=/var/run/spark/$pidWorker
pid_dir=/var/run/spark
sbin=/opt/$sparkVer/sbin
DESC="Spark Worker"
CMD_PATT="spark"
. /lib/lsb/init-functions
. /etc/profile
. $SPARK_HOME/conf/spark-env.sh

export SPARK_PID_DIR=$pid_dir

CMD_PATT="spark"

check_process(){
  if [ $# == 1 ]; then
    role=$1
  elif [ $# == 2 ]; then
    pid_file=$1
    role=$2
  fi

  if [ -f $pid_dir/$pid_file ] && [ "x$pid_file" != "x" ]; then
    pid=`cat $pid_dir/$pid_file`
    if [ -d "/proc/$pid" ]; then
      if grep -Eq "$CMD_PATT" "/proc/$pid/cmdline"; then
        log_success_msg "Spark $role is running (pid:$pid)"
        return 0
      else
        log_failure_msg "$role is NOT running"
        return 1
      fi
    else
       log_failure_msg "$role is NOT running"
    fi
  else
    log_success_msg "$role is NOT running"
    return 0
  fi
}


kill_service(){
  pid_file=$1
  is_running $pid_file
  stat=$?
  if [ "$stat" == "1" ]; then
    start-stop-daemon -K -p "$pid_dir/$pid_file" -R TERM/30/KILL/5 >/dev/null
  fi
  if [ -f $pid_dir/$pid_file ];then
    rm $pid_dir/$pid_file
  fi
}


is_running(){
  pid_file_name=$1
  if [ -f $pid_dir/$pid_file_name ] && [ "x$pid_file_name" != "x" ]; then
    pid=`cat $pid_dir/$pid_file_name`
    if grep -Eq "$CMD_PATT" "/proc/$pid/cmdline"; then
      return 1;
    fi
  fi
  return 0
}


case "$1" in
  start)
    $sbin/start-slave.sh 1 spark://$SPARK_MASTER_IP:7077
    ;;
  stop)
    kill_service $pidWorker
    ;;
  restart)
    $0 stop
    $0 start 
    ;;
  status)
    check_process $pidWorker "Worker"
    ;;	
  kill)
    kill_process $pidWorker
    ;;
  *)
    echo "Usage: $0 {start|stop|restart|status|kill}"
    exit 1
esac

